{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Install Dependencies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96ebce18d578ee29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y ffmpeg\n",
    "!pip install -U openai-whisper jiwer\n",
    "!pip install -U tqdm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97365edacf6fd6ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verify Installation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95cc4187475103f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Whisper loaded:\", whisper.load_model(\"base\") is not None)\n",
    "\n",
    "subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True)\n",
    "print(\"FFmpeg OK\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a6ba7374799d70b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mount Google Drive"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12b9bbbb8e3a2ffa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c339a0388fd9f224"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import and Configuration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b1e25ed339c9857"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "import whisper\n",
    "from jiwer import wer as compute_wer\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    \"cha_dir\": Path(\"content/drive/MyDrive/asr/data/cha\"),\n",
    "    \"audio_dir\": Path(\"content/drive/MyDrive/asr/data/songs\"),\n",
    "    \"output_dir\": Path(\"content/drive/MyDrive/asr/output/whisper_children_dataset\"),\n",
    "    \"whisper_model\": \"base\",\n",
    "    \"sample_size\": None,  # None = tous, ou 500 pour tester\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"sample_rate\": 16000,\n",
    "    \"audio_extensions\": [\".wav\", \".mp3\", \".m4a\", \".flac\"]\n",
    "}\n",
    "\n",
    "# CHILDES roles\n",
    "CHILD_ROLES = {\"Target_Child\", \"Child\", \"Sibling\", \"Peer\", \"Playmate\"}\n",
    "ADULT_ROLES = {\"Investigator\", \"Teacher\", \"Mother\", \"Father\", \"Adult\", \"Caregiver\", \"Parent\"}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f70d298f1e0c664f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zone 1: File Matching"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7559a2d627494c09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "COMPLETE PIPELINE NOTEBOOK\n",
    "Input: Dataset folders (data/ca + data/songs)\n",
    "Output: Training dataset for Whisper fine-tuning (children voices only)\n",
    "\n",
    "Flow:\n",
    "1. Match .cha â†” Audio files\n",
    "2. Extract .cha segments (word-level timestamps)\n",
    "3. Segment audio files based on timestamps\n",
    "4. Evaluate Whisper baseline (children only)\n",
    "5. Calculate WER (children only)\n",
    "6. Create training dataset (JSONL + metadata)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67462b483668a4bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Union\n",
    "\n",
    "@dataclass\n",
    "class WorSegment:\n",
    "    speaker: str\n",
    "    text: str\n",
    "    words: list  # [(word, start, end)]\n",
    "    file_name: str = \"\"  # Ajouter le nom du fichier source\n",
    "\n",
    "\n",
    "def extract_wor_segments(path: Union[Path, str], debug: bool = False) -> List[WorSegment]:\n",
    "    \"\"\"\n",
    "    Extraire segments %wor d'un fichier .cha\n",
    "\n",
    "    Args:\n",
    "        path: Chemin vers un fichier .cha OU un dossier contenant des .cha\n",
    "        debug: Afficher les infos de parsing\n",
    "\n",
    "    Returns:\n",
    "        Liste de WorSegment\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "\n",
    "    if path.is_dir():\n",
    "        # Si c'est un dossier, traiter tous les .cha\n",
    "        return _extract_from_directory(path, debug=debug)\n",
    "    elif path.is_file():\n",
    "        # Si c'est un fichier, le traiter\n",
    "        return _extract_from_file(path, debug=debug)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Chemin invalide: {path}\")\n",
    "\n",
    "\n",
    "def _extract_from_directory(cha_dir: Path, debug: bool = False) -> List[WorSegment]:\n",
    "    \"\"\"Extraire de tous les fichiers .cha d'un dossier (rÃ©cursivement)\"\"\"\n",
    "\n",
    "    # Chercher les .cha dans le dossier ET les sous-dossiers\n",
    "    cha_files = sorted(cha_dir.glob(\"*.cha\")) + sorted(cha_dir.glob(\"**/*.cha\"))\n",
    "    # Enlever les doublons\n",
    "    cha_files = sorted(set(cha_files))\n",
    "\n",
    "    if not cha_files:\n",
    "        print(f\"âš ï¸  Aucun fichier .cha trouvÃ© dans {cha_dir}\")\n",
    "        return []\n",
    "\n",
    "    if debug:\n",
    "        print(f\"ðŸ“ Traitement de {len(cha_files)} fichiers .cha\\n\")\n",
    "\n",
    "    all_segments = []\n",
    "\n",
    "    for cha_file in cha_files:\n",
    "        if debug:\n",
    "            print(f\"  ðŸ”„ {cha_file.name}...\", end=\" \")\n",
    "\n",
    "        segments = _extract_from_file(cha_file, debug=False)\n",
    "        all_segments.extend(segments)\n",
    "\n",
    "        if debug:\n",
    "            print(f\"âœ“ ({len(segments)} segments)\")\n",
    "\n",
    "    if debug:\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"Total: {len(all_segments)} segments de {len(cha_files)} fichiers\")\n",
    "        print(f\"{'=' * 60}\\n\")\n",
    "\n",
    "    return all_segments\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "519ecf07a4bc9b62"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def _extract_from_file(cha_file: Path, debug: bool = False) -> List[WorSegment]:\n",
    "    \"\"\"Extraire de un seul fichier .cha\"\"\"\n",
    "\n",
    "    segments = []\n",
    "    current_speaker = None\n",
    "    file_name = cha_file.stem\n",
    "\n",
    "    with cha_file.open(encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "\n",
    "            # â”€â”€ tour principal\n",
    "            if line.startswith(\"*\"):\n",
    "                current_speaker = line.split(\":\", 1)[0].replace(\"*\", \"\").strip()\n",
    "\n",
    "            # â”€â”€ word tier\n",
    "            elif line.startswith(\"%wor:\"):\n",
    "                if not current_speaker:\n",
    "                    continue\n",
    "\n",
    "                # Extraire la partie aprÃ¨s \"%wor:\"\n",
    "                wor_content = line.split(\":\", 1)[1].strip()\n",
    "\n",
    "                # Nettoyer les caractÃ¨res de contrÃ´le\n",
    "                wor_content = wor_content.replace('\\x15', '')\n",
    "\n",
    "                # Parser simple : splitter par espaces et apparier word + timestamp\n",
    "                tokens = wor_content.split()\n",
    "\n",
    "                words = []\n",
    "                i = 0\n",
    "                while i < len(tokens):\n",
    "                    token = tokens[i]\n",
    "\n",
    "                    # VÃ©rifier si c'est un timestamp (format XXXXX_XXXXX)\n",
    "                    if re.match(r\"^\\d{5,}_\\d{5,}$\", token):\n",
    "                        # C'est un timestamp â†’ l'attacher au mot prÃ©cÃ©dent\n",
    "                        if words:\n",
    "                            word, _, _ = words[-1]\n",
    "                            match = re.match(r\"(\\d+)_(\\d+)\", token)\n",
    "                            if match:\n",
    "                                start, end = int(match.group(1)), int(match.group(2))\n",
    "                                words[-1] = (word, start, end)\n",
    "                        i += 1\n",
    "                        continue\n",
    "\n",
    "                    # Sinon, c'est un mot\n",
    "                    words.append((token, None, None))\n",
    "                    i += 1\n",
    "\n",
    "                # Filtrer : garder seulement les mots avec timestamps\n",
    "                words_with_ts = [(w, s, e) for w, s, e in words if s is not None and e is not None]\n",
    "\n",
    "                if not words_with_ts:\n",
    "                    continue\n",
    "\n",
    "                # Nettoyer le texte : enlever les ponctuations isolÃ©es\n",
    "                clean_words = [w for w, _, _ in words_with_ts if w not in ('?', '.', ',', '!', '+...')]\n",
    "\n",
    "                if clean_words:\n",
    "                    clean_text = \" \".join(clean_words)\n",
    "\n",
    "                    segments.append(\n",
    "                        WorSegment(\n",
    "                            speaker=current_speaker,\n",
    "                            text=clean_text,\n",
    "                            words=words_with_ts,\n",
    "                            file_name=file_name\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    if debug and len(segments) <= 3:\n",
    "                        print(f\"\\nâœ”ï¸ {current_speaker}\")\n",
    "                        print(f\"   Text: {clean_text[:70]}\")\n",
    "                        print(f\"   Words: {words_with_ts[:3]}...\")\n",
    "\n",
    "    if debug:\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"Total segments ({file_name}): {len(segments)}\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "\n",
    "    return segments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c0067a8814b550f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_statistics(segments: List[WorSegment]):\n",
    "    \"\"\"Afficher statistiques dÃ©taillÃ©es sur les segments\"\"\"\n",
    "\n",
    "    if not segments:\n",
    "        print(\"âŒ Aucun segment trouvÃ©\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"ðŸ“Š STATISTIQUES\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Par speaker\n",
    "    by_speaker = {}\n",
    "    by_file = {}\n",
    "\n",
    "    for seg in segments:\n",
    "        # Par speaker\n",
    "        by_speaker.setdefault(seg.speaker, []).append(seg)\n",
    "\n",
    "        # Par fichier\n",
    "        by_file.setdefault(seg.file_name, []).append(seg)\n",
    "\n",
    "    print(f\"\\nðŸ‘¥ Par speaker ({len(by_speaker)} speakers):\")\n",
    "    for speaker in sorted(by_speaker.keys()):\n",
    "        segs = by_speaker[speaker]\n",
    "        total_duration = sum(s.words[-1][2] - s.words[0][1] for s in segs) / 1000\n",
    "        print(f\"   {speaker:20} {len(segs):3d} segments | {total_duration:6.1f}s audio\")\n",
    "\n",
    "    print(f\"\\nðŸ“ Par fichier ({len(by_file)} fichiers):\")\n",
    "    for file_name in sorted(by_file.keys()):\n",
    "        segs = by_file[file_name]\n",
    "        total_duration = sum(s.words[-1][2] - s.words[0][1] for s in segs) / 1000\n",
    "        print(f\"   {file_name:30} {len(segs):3d} segments | {total_duration:6.1f}s audio\")\n",
    "\n",
    "    # Stats globales\n",
    "    total_duration = sum(s.words[-1][2] - s.words[0][1] for s in segments) / 1000 / 60\n",
    "    avg_words = sum(len(s.words) for s in segments) / len(segments)\n",
    "\n",
    "    print(f\"\\nðŸ“ˆ Globales:\")\n",
    "    print(f\"   Total segments: {len(segments)}\")\n",
    "    print(f\"   Total audio: {total_duration:.1f} minutes\")\n",
    "    print(f\"   Mots par segment (moyennes): {avg_words:.1f}\")\n",
    "    print(f\"{'=' * 60}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Exemple 1: Traiter UN fichier\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXEMPLE 1: UN FICHIER\")\n",
    "    print(\"=\" * 60)\n",
    "    segments_single = extract_wor_segments(Path(\"data/2/01-1a.cha\"), debug=True)\n",
    "\n",
    "    # Exemple 2: Traiter UN DOSSIER ENTIER\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EXEMPLE 2: DOSSIER ENTIER\")\n",
    "    print(\"=\" * 60)\n",
    "    segments_all = extract_wor_segments(Path(\"data\"), debug=True)\n",
    "\n",
    "    # Afficher statistiques\n",
    "    print_statistics(segments_all)\n",
    "\n",
    "    # Exemples\n",
    "    if segments_all:\n",
    "        print(f\"{'=' * 60}\")\n",
    "        print(\"EXEMPLES DE SEGMENTS:\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "        for i, seg in enumerate(segments_all[:5]):\n",
    "            print(f\"\\n[{i + 1}] {seg.speaker} ({seg.file_name})\")\n",
    "            print(f\"  Text: {seg.text}\")\n",
    "            if seg.words:\n",
    "                print(f\"  Time: {seg.words[0][1]} â†’ {seg.words[-1][2]} ms\")\n",
    "                print(f\"  Words: {seg.words[:3]}...\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47b2fd6c188fbf24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_matching_files(cha_dir: Path, audio_dir: Path, extensions: List[str]) -> Dict:\n",
    "    \"\"\"Match .cha with audio files, ignore orphans\"\"\"\n",
    "    \n",
    "    cha_files = sorted(cha_dir.glob(\"**/*.cha\"))\n",
    "    cha_stems = {f.stem: f for f in cha_files}\n",
    "    \n",
    "    audio_files = []\n",
    "    for ext in extensions:\n",
    "        audio_files.extend(audio_dir.glob(f\"**/*{ext}\"))\n",
    "    audio_stems = {f.stem: f for f in audio_files}\n",
    "    \n",
    "    matched = [(cha_stems[stem], audio_stems[stem]) \n",
    "               for stem in cha_stems if stem in audio_stems]\n",
    "    cha_missing = [cha for stem, cha in cha_stems.items() if stem not in audio_stems]\n",
    "    \n",
    "    return {\n",
    "        \"matched\": matched,\n",
    "        \"cha_missing_audio\": cha_missing,\n",
    "        \"total_cha\": len(cha_files),\n",
    "        \"total_audio\": len(audio_files),\n",
    "        \"matched_count\": len(matched)\n",
    "    }\n",
    "\n",
    "\n",
    "def print_matching_report(result: Dict):\n",
    "    \"\"\"Afficher le rapport de matching\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ“Š STEP 1: FILE MATCHING\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nðŸ“ Found:\")\n",
    "    print(f\"   Total .cha files:    {result['total_cha']}\")\n",
    "    print(f\"   Total audio files:   {result['total_audio']}\")\n",
    "    print(f\"   âœ… Matched pairs:     {result['matched_count']}\")\n",
    "    print(f\"   âš ï¸  .cha missing audio: {len(result['cha_missing_audio'])}\")\n",
    "    \n",
    "    if result['cha_missing_audio']:\n",
    "        print(f\"\\n   Skipped .cha files:\")\n",
    "        for cha in result['cha_missing_audio'][:5]:\n",
    "            print(f\"      - {cha.name}\")\n",
    "        if len(result['cha_missing_audio']) > 5:\n",
    "            print(f\"      ... and {len(result['cha_missing_audio']) - 5} more\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd3a77bf04214636"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zone 2: Segment Extraction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c14693053fe52933"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_segments_from_matched(matched_pairs: List[Tuple[Path, Path]]) -> List[WorSegment]:\n",
    "    \"\"\"Extract .cha segments from matched files only\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ðŸ“ STEP 2: EXTRACT .CHA SEGMENTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    all_segments = []\n",
    "    \n",
    "    for i, (cha_file, audio_file) in enumerate(matched_pairs):\n",
    "        segments = extract_wor_segments(cha_file, debug=False)\n",
    "        all_segments.extend(segments)\n",
    "        \n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"  âœ“ {i + 1}/{len(matched_pairs)} files\")\n",
    "    \n",
    "    print(f\"\\nâœ… Extracted {len(all_segments)} segments with timestamps\\n\")\n",
    "    return all_segments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a740ee2268e7c80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zone 3: Audio Segmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8c46df2bd7edb24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AudioSegmenter:\n",
    "    \"\"\"Segment audio files based on timestamps\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: Path, sample_rate: int = 16000):\n",
    "        self.output_dir = output_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.speaker_dirs = {}\n",
    "    \n",
    "    def _get_speaker_dir(self, speaker: str) -> Path:\n",
    "        if speaker not in self.speaker_dirs:\n",
    "            d = self.output_dir / speaker\n",
    "            d.mkdir(exist_ok=True)\n",
    "            self.speaker_dirs[speaker] = d\n",
    "        return self.speaker_dirs[speaker]\n",
    "    \n",
    "    def extract_segment(self, audio_file: Path, start_ms: int, end_ms: int, output_path: Path) -> bool:\n",
    "        \"\"\"Extract audio segment using ffmpeg\"\"\"\n",
    "        if not audio_file.exists():\n",
    "            return False\n",
    "        \n",
    "        start_sec = start_ms / 1000.0\n",
    "        duration_sec = (end_ms - start_ms) / 1000.0\n",
    "        \n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-i\", str(audio_file),\n",
    "            \"-ss\", str(start_sec), \"-t\", str(duration_sec),\n",
    "            \"-acodec\", \"pcm_s16le\", \"-ar\", str(self.sample_rate), \"-ac\", \"1\",\n",
    "            \"-y\", str(output_path)\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(cmd, check=True, capture_output=True, timeout=10)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def segment_all(self, segments: List[WorSegment], matched_pairs: List[Tuple[Path, Path]]) -> List[Dict]:\n",
    "        \"\"\"Segment all audio files\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"ðŸŽµ STEP 3: SEGMENT AUDIO FILES\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        audio_lookup = {audio.stem: audio for _, audio in matched_pairs}\n",
    "        \n",
    "        results = []\n",
    "        skipped = 0\n",
    "        \n",
    "        for i, seg in enumerate(segments):\n",
    "            audio_file = audio_lookup.get(seg.file_name)\n",
    "            if not audio_file or not audio_file.exists():\n",
    "                skipped += 1\n",
    "                continue\n",
    "            \n",
    "            segment_id = f\"{seg.file_name}_{seg.speaker}_{i:05d}\"\n",
    "            speaker_dir = self._get_speaker_dir(seg.speaker)\n",
    "            output_path = speaker_dir / f\"{segment_id}.wav\"\n",
    "            \n",
    "            start_ms = seg.words[0][1]\n",
    "            end_ms = seg.words[-1][2]\n",
    "            \n",
    "            if self.extract_segment(audio_file, start_ms, end_ms, output_path):\n",
    "                results.append({\n",
    "                    \"segment_id\": segment_id,\n",
    "                    \"speaker\": seg.speaker,\n",
    "                    \"file_name\": seg.file_name,\n",
    "                    \"audio_path\": str(output_path),\n",
    "                    \"duration_ms\": end_ms - start_ms,\n",
    "                    \"text\": seg.text,\n",
    "                    \"num_words\": len(seg.words)\n",
    "                })\n",
    "            \n",
    "            if (i + 1) % 200 == 0:\n",
    "                print(f\"  âœ“ {i + 1}/{len(segments)} segments\")\n",
    "        \n",
    "        print(f\"\\nâœ… Segmented {len(results)} audio files\\n\")\n",
    "        return results\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80497d00e612e1b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zone 4: Extract Speakers Metadata"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "943d4e4e3bfda994"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_all_speakers_info(matched_pairs: List[Tuple[Path, Path]]) -> Dict[str, str]:\n",
    "    \"\"\"Extract speaker roles from all .cha files\"\"\"\n",
    "    \n",
    "    all_speakers = {}\n",
    "    \n",
    "    for cha_file, _ in matched_pairs:\n",
    "        with cha_file.open(encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"@Participants:\"):\n",
    "                    participants_str = line.split(\":\", 1)[1].strip()\n",
    "                    for participant in participants_str.split(\",\"):\n",
    "                        participant = participant.strip()\n",
    "                        parts = participant.rsplit(\" \", 1)\n",
    "                        if len(parts) == 2:\n",
    "                            speaker_name, role = parts\n",
    "                            all_speakers[speaker_name] = role\n",
    "    \n",
    "    return all_speakers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8396f12238990506"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zone 5: Whisper Baseline Evaluation Compute of the WER before fine-tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12fa0821d60383a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Whisper Evaluation Class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d74957261de05d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TranscriptionResult:\n",
    "    segment_id: str\n",
    "    speaker: str\n",
    "    file_name: str\n",
    "    audio_path: str\n",
    "    ground_truth: str\n",
    "    whisper_prediction: str\n",
    "    duration_ms: int\n",
    "    wer: float\n",
    "    confidence: float = 0.0\n",
    "\n",
    "\n",
    "class WhisperEvaluator:\n",
    "    \"\"\"Evaluate Whisper baseline on children voices\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"base\"):\n",
    "        print(f\"ðŸ“¦ Loading Whisper '{model_name}'...\")\n",
    "        self.model = whisper.load_model(model_name)\n",
    "        print(\"âœ“ Loaded\\n\")\n",
    "    \n",
    "    def transcribe(self, audio_path: Path) -> Dict:\n",
    "        if not audio_path.exists():\n",
    "            return {\"text\": \"\", \"confidence\": 0.0}\n",
    "        try:\n",
    "            result = self.model.transcribe(str(audio_path), language=\"fr\", verbose=False)\n",
    "            return {\"text\": result[\"text\"].strip(), \"confidence\": result.get(\"confidence\", 0.0)}\n",
    "        except:\n",
    "            return {\"text\": \"\", \"confidence\": 0.0}\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_wer(ground_truth: str, prediction: str) -> float:\n",
    "        if not ground_truth.strip():\n",
    "            return 0.0 if not prediction.strip() else 1.0\n",
    "        return compute_wer(ground_truth, prediction)\n",
    "    \n",
    "    def evaluate_children(self, audio_segments: List[Dict], speakers_info: Dict, \n",
    "                         sample_size: int = None) -> List[TranscriptionResult]:\n",
    "        \"\"\"Evaluate only children speakers\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"ðŸŽ¤ STEP 4: WHISPER BASELINE EVALUATION (CHILDREN ONLY)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Filter children only\n",
    "        children_segments = [s for s in audio_segments \n",
    "                            if speakers_info.get(s[\"speaker\"]) in CHILD_ROLES]\n",
    "        \n",
    "        if sample_size:\n",
    "            children_segments = children_segments[:sample_size]\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Evaluating {len(children_segments)} children segments\\n\")\n",
    "        \n",
    "        results = []\n",
    "        for i, seg in enumerate(children_segments):\n",
    "            audio_path = Path(seg[\"audio_path\"])\n",
    "            transcription = self.transcribe(audio_path)\n",
    "            wer = self.calculate_wer(seg[\"text\"], transcription[\"text\"])\n",
    "            \n",
    "            results.append(TranscriptionResult(\n",
    "                segment_id=seg[\"segment_id\"],\n",
    "                speaker=seg[\"speaker\"],\n",
    "                file_name=seg[\"file_name\"],\n",
    "                audio_path=seg[\"audio_path\"],\n",
    "                ground_truth=seg[\"text\"],\n",
    "                whisper_prediction=transcription[\"text\"],\n",
    "                duration_ms=seg[\"duration_ms\"],\n",
    "                wer=wer,\n",
    "                confidence=transcription[\"confidence\"]\n",
    "            ))\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                avg_wer = sum(r.wer for r in results) / len(results)\n",
    "                print(f\"  âœ“ {i + 1}/{len(children_segments)} | Avg WER: {avg_wer:.3f}\")\n",
    "        \n",
    "        return results\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f0f5c05dcf4a3ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### WER Report"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74cade2ed08b42c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def print_wer_report(results: List[TranscriptionResult], speakers_info: Dict):\n",
    "    \"\"\"Print WER statistics\"\"\"\n",
    "    \n",
    "    wers = [r.wer for r in results]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ“ˆ STEP 5: WER STATISTICS (CHILDREN ONLY)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Global:\")\n",
    "    print(f\"   Total segments:  {len(results)}\")\n",
    "    print(f\"   Avg WER:         {sum(wers) / len(wers):.3f}\")\n",
    "    print(f\"   Min WER:         {min(wers):.3f}\")\n",
    "    print(f\"   Max WER:         {max(wers):.3f}\")\n",
    "    print(f\"   Median WER:      {sorted(wers)[len(wers)//2]:.3f}\")\n",
    "    \n",
    "    print(f\"\\n   Distribution:\")\n",
    "    for low, high in [(0.0, 0.1), (0.1, 0.3), (0.3, 0.5), (0.5, 1.0)]:\n",
    "        count = sum(1 for w in wers if low <= w < high)\n",
    "        pct = (count / len(wers)) * 100\n",
    "        print(f\"      {low:.1f}-{high:.1f}: {count:4d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # By speaker\n",
    "    by_speaker = {}\n",
    "    for r in results:\n",
    "        by_speaker.setdefault(r.speaker, []).append(r.wer)\n",
    "    \n",
    "    print(f\"\\nðŸ‘¥ By speaker ({len(by_speaker)}):\")\n",
    "    for speaker in sorted(by_speaker.keys()):\n",
    "        wers_sp = by_speaker[speaker]\n",
    "        avg = sum(wers_sp) / len(wers_sp)\n",
    "        print(f\"      {speaker:15} {len(wers_sp):4d} segments | WER: {avg:.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79b8d8b8b8619ebb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zone 6: Create Training Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e608ae279a9c06a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DatasetBuilder:\n",
    "    \"\"\"Create train/test splits for fine-tuning\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: Path):\n",
    "        self.output_dir = output_dir\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def create_dataset(self, results: List[TranscriptionResult], train_ratio: float = 0.8):\n",
    "        \"\"\"Create JSONL + metadata files\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"ðŸ“¦ STEP 6: CREATE TRAINING DATASET\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        split_idx = int(len(results) * train_ratio)\n",
    "        train = results[:split_idx]\n",
    "        test = results[split_idx:]\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Dataset split:\")\n",
    "        print(f\"   Total:   {len(results)} segments\")\n",
    "        print(f\"   Train:   {len(train)} segments ({train_ratio*100:.0f}%)\")\n",
    "        print(f\"   Test:    {len(test)} segments ({(1-train_ratio)*100:.0f}%)\")\n",
    "        \n",
    "        # Save JSONL (for fine-tuning)\n",
    "        self._save_jsonl(train, self.output_dir / \"train.jsonl\")\n",
    "        self._save_jsonl(test, self.output_dir / \"eval.jsonl\")\n",
    "        \n",
    "        # Save metadata JSON (for analysis)\n",
    "        self._save_metadata(train, self.output_dir / \"train_metadata.json\")\n",
    "        self._save_metadata(test, self.output_dir / \"eval_metadata.json\")\n",
    "        \n",
    "        print(f\"\\nâœ… Dataset created in {self.output_dir}\\n\")\n",
    "    \n",
    "    def _save_jsonl(self, results: List[TranscriptionResult], output_file: Path):\n",
    "        \"\"\"Save as JSONL for Whisper\"\"\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            for r in results:\n",
    "                entry = {\"audio\": r.audio_path, \"text\": r.ground_truth, \"language\": \"fr\"}\n",
    "                f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "        print(f\"   âœ“ {output_file.name} ({len(results)} segments)\")\n",
    "    \n",
    "    def _save_metadata(self, results: List[TranscriptionResult], output_file: Path):\n",
    "        \"\"\"Save complete metadata\"\"\"\n",
    "        data = [asdict(r) for r in results]\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"   âœ“ {output_file.name}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12ce2b08fa79f652"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MAIN PIPELINE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46f53541369e0d97"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_pipeline():\n",
    "    \"\"\"Run complete pipeline end-to-end\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸš€ COMPLETE WHISPER CHILDREN DATASET PIPELINE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ZONE 1: Matching\n",
    "    match_result = find_matching_files(CONFIG[\"cha_dir\"], CONFIG[\"audio_dir\"], CONFIG[\"audio_extensions\"])\n",
    "    print_matching_report(match_result)\n",
    "    \n",
    "    if not match_result[\"matched\"]:\n",
    "        print(\" No matched pairs found!\")\n",
    "        return\n",
    "    \n",
    "    # ZONE 2: Extract segments\n",
    "    segments = extract_segments_from_matched(match_result[\"matched\"])\n",
    "    \n",
    "    # ZONE 3: Segment audio\n",
    "    segmenter = AudioSegmenter(CONFIG[\"output_dir\"] / \"audio_segments\")\n",
    "    audio_segments = segmenter.segment_all(segments, match_result[\"matched\"])\n",
    "    \n",
    "    # ZONE 4: Get speakers info\n",
    "    speakers_info = extract_all_speakers_info(match_result[\"matched\"])\n",
    "    \n",
    "    # ZONE 5: Evaluate Whisper (children only)\n",
    "    evaluator = WhisperEvaluator(CONFIG[\"whisper_model\"])\n",
    "    results = evaluator.evaluate_children(audio_segments, speakers_info, CONFIG[\"sample_size\"])\n",
    "    \n",
    "    print_wer_report(results, speakers_info)\n",
    "    \n",
    "    # ZONE 6: Create dataset\n",
    "    builder = DatasetBuilder(CONFIG[\"output_dir\"] / \"training_dataset\")\n",
    "    builder.create_dataset(results, CONFIG[\"train_ratio\"])\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"âœ… PIPELINE COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nðŸ“‚ Output directory: {CONFIG['output_dir']}\")\n",
    "    print(\"\\nðŸ“‹ Files generated:\")\n",
    "    print(\"   training_dataset/train.jsonl ........... for fine-tuning\")\n",
    "    print(\"   training_dataset/eval.jsonl ........... for evaluation\")\n",
    "    print(\"   training_dataset/train_metadata.json .. complete metadata\")\n",
    "    print(\"   training_dataset/eval_metadata.json ... complete metadata\")\n",
    "    print(\"\\nðŸŽ“ Ready for Whisper fine-tuning!\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5d5ac8b292fc833"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
